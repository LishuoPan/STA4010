{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy is the very basic package in python\n",
    "# sklearn contain the original SVM\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the training dataset is: (4000, 10)\n",
      "(4000,)\n",
      "the size of the testing dataset is: (400, 10)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "# fix the seed\n",
    "np.random.seed(1)\n",
    "## generate the dataset\n",
    "# the dimension and size of the data\n",
    "p = 10\n",
    "n_train = 2000\n",
    "n_test = 200\n",
    "\n",
    "\n",
    "# two distribution we sample data from\n",
    "mu1 = np.repeat(0.5,p)\n",
    "sigma1 = np.eye(p)\n",
    "mu2 = np.repeat(-0.5,p)\n",
    "sigma2 = np.eye(p)\n",
    "\n",
    "# construct the training dataset\n",
    "train_x1 = np.random.multivariate_normal(mu1,sigma1,n_train)\n",
    "train_y1 = np.repeat(1,n_train)\n",
    "\n",
    "train_x2 = np.random.multivariate_normal(mu2,sigma2,n_train)\n",
    "train_y2 = np.repeat(-1,n_train)\n",
    "\n",
    "train_x = np.vstack((train_x1,train_x2))\n",
    "train_y = np.hstack((train_y1,train_y2))\n",
    "\n",
    "print('the size of the training dataset is:',train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "# constructing the testing dataset\n",
    "test_x1 = np.random.multivariate_normal(mu1,sigma1,n_test)\n",
    "test_y1 = np.repeat(1,n_test)\n",
    "\n",
    "test_x2 = np.random.multivariate_normal(mu2,sigma2,n_test)\n",
    "test_y2 = np.repeat(-1,n_test)\n",
    "\n",
    "test_x = np.vstack((test_x1,test_x2))\n",
    "test_y = np.hstack((test_y1,test_y2))\n",
    "\n",
    "print('the size of the testing dataset is:',test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Accuracy of SVM: 0.935\n",
      "Time for performance SVM: 0.13187074661254883 s\n"
     ]
    }
   ],
   "source": [
    "## T1\n",
    "# construct SVM from sklearn package\n",
    "time_start = time.time()\n",
    "model = svm.SVC(kernel=\"rbf\")\n",
    "print(model.fit(train_x,train_y))\n",
    "pred = model.predict(test_x)\n",
    "# compute the accuracy of our SVM model\n",
    "accu = sum(pred == test_y)/len(test_y)\n",
    "print(\"Accuracy of SVM:\",accu)\n",
    "# compute the time epoch\n",
    "print(\"Time for performance SVM:\",time.time()-time_start,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argumented dimension after adding bias column:\n",
      " (4000, 11) (400, 11)\n",
      "1002 iteration: Optimal find\n",
      "beta:\n",
      " [0.25755508 0.26298576 0.23128091 0.25647379 0.25701372 0.21696959\n",
      " 0.27952904 0.26042558 0.25392188 0.22442451]\n",
      "Accuracy of SGD: 0.9425\n",
      "Time for performance SGD: 0.017499923706054688 s\n"
     ]
    }
   ],
   "source": [
    "## T2\n",
    "# adding column one at the front of the matrix\n",
    "add_train = np.repeat(1,2*n_train).reshape(-1,1)\n",
    "arg_train_x = np.hstack((add_train,train_x))\n",
    "\n",
    "add_test = np.repeat(1,2*n_test).reshape(-1,1)\n",
    "arg_test_x = np.hstack((add_test,test_x))\n",
    "\n",
    "print(\"argumented dimension after adding bias column:\\n\"\n",
    "      ,arg_train_x.shape,arg_test_x.shape)\n",
    "# hyper-parameter settings\n",
    "C = 1\n",
    "beta = np.repeat(0.1,p)\n",
    "MAX_L = 10000\n",
    "# step size\n",
    "mu = 0.001\n",
    "\n",
    "# mapping function and gradient function\n",
    "def mapping(x):\n",
    "    mapping = x\n",
    "    return mapping\n",
    "def gradient(x,y,beta):\n",
    "    indicator = y*x@beta - 1\n",
    "    if indicator<0:\n",
    "        g = -y*x\n",
    "        \n",
    "    else:\n",
    "        g = 0\n",
    "    return g\n",
    "# start counting time for SGD\n",
    "time_start_sgd = time.time()\n",
    "# one SGD sample approach. Training stage of the model \n",
    "for i in range(MAX_L):\n",
    "    index = np.random.randint(4000)\n",
    "    x = train_x[index,]\n",
    "    y = train_y[index]\n",
    "    z = beta - mu * gradient(x,y,beta)\n",
    "    # introduce the stopping criteria, \n",
    "    # meanwhile gaurantee the loop goes for a while\n",
    "    # because we may sample a point which not change the beta\n",
    "    if i > 1000:\n",
    "        if max(z-beta) < 0.0001:\n",
    "            print(i,'iteration: Optimal find')\n",
    "            break\n",
    "    beta = z\n",
    "print(\"beta:\\n\",beta)\n",
    "\n",
    "# prediction stage of the model, \n",
    "# assess the performance in terms of accuracy and time consumption\n",
    "pred_SGD = list()\n",
    "for i in range(2*n_test):\n",
    "    if test_x[i,]@beta > 0:\n",
    "        pred_SGD.append(1)\n",
    "    else:\n",
    "        pred_SGD.append(-1)\n",
    "# print(np.array(pred_SGD))\n",
    "# print(test_y)\n",
    "accu = sum(np.array(pred_SGD) == test_y)/len(test_y)\n",
    "print(\"Accuracy of SGD:\",accu)\n",
    "# compute the time epoch\n",
    "print(\"Time for performance SGD:\",time.time()-time_start_sgd,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare & comment\n",
    "## compare: \n",
    "\n",
    "### the time taken by SGD case is much shorter than the original SVM model. simply because we take in only one data point at a time, the time complexity is $O(iteration)$ but for the SVM case the time complexity is $O(n)$ so there is a time boost in SGD case.\n",
    "### Meanwhile, we can see that the performance of SGD is about the same or a little higher than the SVM package in sklearn under the same hyperparameter C. \n",
    "\n",
    "## comment: \n",
    "\n",
    "### SGD method is a good way to implement SVM, because of its time complexity and accuracy performance.\n",
    "### we can find out that in the SGD case. To simplify the problem and reduce the computational complexity, I did not use the mapping h(x). I directly use the x. Maybe a proper h(x) can boost the performance of SGD again.\n",
    "### Higher performance maybe due to the reason that SGD is actually not finding the optimal of the original problem rather a ball around the optimal. So, this means when the case happens that the original SVM with the hyperparameter which is overfitting. The SGD is like a regulation to the optimal problem. Thus having a higher performance in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "603px",
    "left": "835px",
    "right": "20px",
    "top": "120px",
    "width": "380px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
